syntax = "proto3";

package cloud.planton.apis.code2cloud.v1.kafka.model;

import "buf/validate/validate.proto";
import "cloud/planton/apis/code2cloud/v1/kubecluster/enums/workloadingress/workload_ingress.proto";
import "cloud/planton/apis/code2cloud/v1/environment/model/state.proto";
import "cloud/planton/apis/commons/apiresource/model/state.proto";
import "cloud/planton/apis/commons/kubernetes/model/state.proto";
import "cloud/planton/apis/commons/apiresource/options/apiresourcefieldoptions/api_resource_field_options.proto";
import "cloud/planton/apis/commons/apiresource/options/apiresourcemetadataoptions/api_resource_metadata_message_options.proto";
import "cloud/planton/apis/commons/apiresource/model/state.proto";
import "cloud/planton/apis/commons/apiresource/options/apiresourcemessageoptions/api_resource_message_options.proto";

//kafka-cluster
message KafkaCluster {
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.resource_kind) = kafka_cluster;
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.is_runnable) = true;
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.owner).resource_kind = environment;
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.owner).id_field_path = "spec.environment_info.environment_id";

  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.apiresourcemetadataoptions.is_id_required) = false;
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.apiresourcemetadataoptions.id_prefix) = "kfc";
  //id format "kfc-<environment-id>-<kafka-cluster-name>"
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.apiresourcemetadataoptions.is_id_computed) = true;

  //resource api-version
  string api_version = 1 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //resource kind
  string kind = 2 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //resource metadata
  cloud.planton.apis.commons.apiresource.model.ApiResourceMetadata metadata = 3 [
    (buf.validate.field).string.min_len = 1,
    (buf.validate.field).string.max_len = 10,
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Only lowercase letters, numbers, and hyphens are allowed",
      // https://regex101.com/r/NKTohE/1
      expression: "this.name.matches('^[a-z0-9-]+$')"
    },
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Must start with a lowercase letter",
      // https://regex101.com/r/qpK7XF/1
      expression: "this.name.matches('^[a-z].*$')"
    },
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Must not end with a hyphen",
      // https://regex101.com/r/reQjcB/1
      expression: "this.name.matches('[^-]$')"
    }
  ];

  //spec
  KafkaClusterSpec spec = 4;

  //status
  KafkaClusterStatus status = 5;
}

//kafka-cluster spec
message KafkaClusterSpec {
  //resource parent
  cloud.planton.apis.code2cloud.v1.environment.model.ResourceEnvironmentInfo environment_info = 1;

  //list of kafka topics.
  repeated KafkaTopic kafka_topics = 2;

  //kubernetes spec
  KafkaClusterSpecKubernetesSpec kubernetes = 3;
}

//kafka-cluster status
message KafkaClusterStatus {
  // resource lifecycle
  cloud.planton.apis.commons.apiresource.model.RunnableResourceLifecycle lifecycle = 99;

  // resource audit info
  cloud.planton.apis.commons.apiresource.model.ApiResourceAudit audit = 98;

  // id of the stack-job
  string stack_job_id = 97;

  //kafka-cluster kubernetes status
  KafkaClusterStatusKubernetesStatus kubernetes = 1;
}

//kafka-cluster kubernetes spec
message KafkaClusterSpecKubernetesSpec {
  //kafka-broker container spec
  KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec kafka_broker_container = 1;

  //zookeeper container spec
  KafkaClusterSpecKubernetesSpecZookeeperContainerSpec zookeeper_container = 2;

  //schema-registry container spec
  KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec schema_registry_container = 3;

  //kafka-cluster ingress spec
  KafkaClusterSpecKubernetesSpecIngressSpec ingress = 4;

  //flag to control if kowl dashboard is deployed for the kafka-cluster.
  //defaults to "false".
  bool is_kowl_dashboard_enabled = 5;
}

//kafka-cluster kubernetes kafka-broker spec
message KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec {
  //(optional for create) number of brokers required to setup kafka-cluster.
  //defaults value "1" is set if client sets the value to 0.
  //recommended default value is "1".
  int32 replicas = 1 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //kafka broker container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.commons.kubernetes.model.ContainerResources resources = 2 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //size of the disk to be attached to each broker instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true,
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes zookeeper spec
message KafkaClusterSpecKubernetesSpecZookeeperContainerSpec {
  //number or zookeeper container replicas
  //zookeeper requires latest 3 replicas for high availability(ha) mode.
  //zookeeper is built using raft consensus algorithm.
  //refer to https://raft.github.io/ to learn more on how replica count affect availability.
  int32 replicas = 1 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //zookeeper container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.commons.kubernetes.model.ContainerResources resources = 2 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //size of the disk to be attached to each zookeeper instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true,
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes schema-registry spec
message KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec {
  //flag to control if schema registry is created for the kafka-cluster.
  //defaults to "false".
  bool is_enabled = 1;

  //number of schema registry replicas.
  //recommended default value is "1".
  //this value has no effect if the is_schema_registry_enabled is set to false.
  int32 replicas = 2 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];

  //schema-registry container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.commons.kubernetes.model.ContainerResources resources = 3 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true
  ];
}

//kafka-cluster kubernetes ingress spec
message KafkaClusterSpecKubernetesSpecIngressSpec {
  option (buf.validate.message).cel = {
    id: "ingres.enabled.endpoint_domain_name.mandatory",
    expression: "this.is_enabled && size(this.endpoint_domain_name) == 0"
        "? 'endpoint domain name is mandatory to enable ingress'"
        ": ''"
  };
  option (buf.validate.message).cel = {
    id: "ingres.enabled.ingress_type.mandatory",
    expression: "this.is_enabled && this.ingress_type == 0"
        "? 'ingress type is mandatory to enable ingress'"
        ": ''"
  };
  //toggle to control ingress
  bool is_enabled = 1;
  //ingress type
  cloud.planton.apis.code2cloud.v1.kubecluster.enums.workloadingress.KubernetesWorkloadIngressType ingress_type = 2;
  //endpoint domain to be used for creating internal and external endpoints for kafka-cluster.
  //if the chosen ingress-type is `ingress-controller`, only tls enabled endpoint domains are allowed for creating kafka endpoints.
  string endpoint_domain_name = 3;
}

//kafka-cluster kubernetes status
message KafkaClusterStatusKubernetesStatus {
  //name of the kubernetes namespace in which the kafka-cluster is created.
  string namespace = 1;

  //sasl user name of kafka-cluster.
  //username will be automatically set as 'admin' while creating the kafka-cluster.
  string kafka_sasl_username = 2;

  //external hostname of kafka bootstrap server.
  string external_bootstrap_server_hostname = 3;

  //internal hostname of kafka bootstrap server.
  string internal_bootstrap_server_hostname = 4;

  //external url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string external_schema_registry_url = 5;

  //internal url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string internal_schema_registry_url = 6;

  //external url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string external_kowl_dashboard_url = 7;

  //internal url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string internal_kowl_dashboard_url = 8;
}

//kafka-topic
message KafkaTopic {
  option (cloud.planton.apis.commons.apiresource.options.apiresourcemessageoptions.apiresourcemetadataoptions.id_prefix) = "kft";

  //topic name
  string name = 1 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_required) = true,
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_immutable) = true,
    (buf.validate.field).string.min_len = 1,
    (buf.validate.field).string.max_len = 249,
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Should start with an alphanumeric character",
      // https://regex101.com/r/cXprYc/1
      expression: "this.matches('^[a-zA-Z0-9].*$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Only alphanumeric and ('.', '_' and '-') characters are allowed",
      // https://regex101.com/r/hheWzb/1
      expression: "this.matches('^[a-zA-Z0-9._-]+$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Must not contain '..'",
      // https://regex101.com/r/ILMhoL/1
      expression: "!this.contains('..')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Must not contain non-ASCII characters",
      // https://regex101.com/r/FhCKeZ/1
      expression: "this.matches('^[\x00-\x7F]+$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Should end with an alphanumeric character",
      // https://regex101.com/r/DEA7Of/1
      expression: "this.matches('[a-zA-Z0-9]$')"
    }
  ];

  //topic id
  string id = 2 [
    (cloud.planton.apis.commons.apiresource.options.apiresourcefieldoptions.is_computed) = true
  ];

  //topic partitions.
  //recommended default is 1.
  int32 partitions = 4;

  //topic replicas.
  //recommended default is 1.
  int32 replicas = 5;

  //additional configuration of kafka topic
  //if not provided then default values will be set
  //for example default delete.policy is `delete` and can be set up as `compact`
  map<string, string> config = 6;
}

//wrapper for kafka topic config
message KafkaTopicConfig {
  map<string, string> value = 1;
}
