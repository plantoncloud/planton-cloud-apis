syntax = "proto3";

package cloud.planton.apis.v1.code2cloud.deploy.kafka;

import "buf/validate/validate.proto";
import "cloud/planton/apis/v1/code2cloud/deploy/kubecluster/enums/workloadingress/workload_ingress.proto";
import "cloud/planton/apis/v1/code2cloud/environment/model.proto";
import "cloud/planton/apis/v1/commons/audit/model.proto";
import "cloud/planton/apis/v1/commons/kubernetes/model.proto";
import "cloud/planton/apis/v1/commons/resource/field/options/resource_field_options.proto";
import "cloud/planton/apis/v1/commons/resource/metadata/options/resource_metadata_options.proto";
import "cloud/planton/apis/v1/commons/resource/model.proto";
import "cloud/planton/apis/v1/commons/resource/options/resource_options.proto";
import "cloud/planton/apis/v1/stack/job/model.proto";

//kafka-cluster
message KafkaCluster {
  option (cloud.planton.apis.v1.commons.resource.options.resource_type) = kafka_cluster;
  option (cloud.planton.apis.v1.commons.resource.options.is_runnable) = true;
  option (cloud.planton.apis.v1.commons.resource.options.owner).type = environment;
  option (cloud.planton.apis.v1.commons.resource.options.owner).id_field_path = "spec.environment_info.environment_id";

  option (cloud.planton.apis.v1.commons.resource.metadata.options.is_id_required) = false;
  option (cloud.planton.apis.v1.commons.resource.metadata.options.id_prefix) = "kfc";
  //id format "kfc-<environment-id>-<kafka-cluster-name>"
  option (cloud.planton.apis.v1.commons.resource.metadata.options.is_id_computed) = true;

  //resource api-version
  string api_version = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //resource kind
  string kind = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //resource metadata
  cloud.planton.apis.v1.commons.resource.Metadata metadata = 3 [
    (buf.validate.field).string.min_len = 1,
    (buf.validate.field).string.max_len = 10,
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Only lowercase letters, numbers, and hyphens are allowed",
      // https://regex101.com/r/NKTohE/1
      expression: "this.name.matches('^[a-z0-9-]+$')"
    },
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Must start with a lowercase letter",
      // https://regex101.com/r/qpK7XF/1
      expression: "this.name.matches('^[a-z].*$')"
    },
    (buf.validate.field).cel = {
      id: "metadata.name",
      message: "Must not end with a hyphen",
      // https://regex101.com/r/reQjcB/1
      expression: "this.name.matches('[^-]$')"
    }
  ];

  //spec
  KafkaClusterSpec spec = 4;

  //status
  KafkaClusterStatus status = 5;
}

//kafka-cluster spec
message KafkaClusterSpec {
  //resource parent
  cloud.planton.apis.v1.code2cloud.environment.ResourceEnvironmentInfo environment_info = 1;

  //list of kafka topics.
  repeated KafkaTopic kafka_topics = 2;

  //kubernetes spec
  KafkaClusterSpecKubernetesSpec kubernetes = 3;
}

//kafka-cluster status
message KafkaClusterStatus {
  // resource lifecycle
  cloud.planton.apis.v1.commons.resource.RunnableResourceLifecycle lifecycle = 99;

  // resource audit info
  cloud.planton.apis.v1.commons.audit.ResourceAudit audit = 98;

  // resource version-id
  string version_id = 97;

  // id of the stack-job
  string stack_job_id = 96;

  //kafka-cluster kubernetes status
  KafkaClusterStatusKubernetesStatus kubernetes = 1;
}

//kafka-cluster kubernetes spec
message KafkaClusterSpecKubernetesSpec {
  //kafka-broker container spec
  KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec kafka_broker_container = 1;

  //zookeeper container spec
  KafkaClusterSpecKubernetesSpecZookeeperContainerSpec zookeeper_container = 2;

  //schema-registry container spec
  KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec schema_registry_container = 3;

  //kafka-cluster ingress spec
  KafkaClusterSpecKubernetesSpecIngressSpec ingress = 4;

  //flag to control if kowl dashboard is deployed for the kafka-cluster.
  //defaults to "false".
  bool is_kowl_dashboard_enabled = 5;
}

//kafka-cluster kubernetes kafka-broker spec
message KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec {
  //(optional for create) number of brokers required to setup kafka-cluster.
  //defaults value "1" is set if client sets the value to 0.
  //recommended default value is "1".
  int32 replicas = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //kafka broker container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.v1.commons.kubernetes.ContainerResources resources = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //size of the disk to be attached to each broker instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true,
    (cloud.planton.apis.v1.commons.resource.field.options.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes zookeeper spec
message KafkaClusterSpecKubernetesSpecZookeeperContainerSpec {
  //number or zookeeper container replicas
  //zookeeper requires latest 3 replicas for high availability(ha) mode.
  //zookeeper is built using raft consensus algorithm.
  //refer to https://raft.github.io/ to learn more on how replica count affect availability.
  int32 replicas = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //zookeeper container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.v1.commons.kubernetes.ContainerResources resources = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //size of the disk to be attached to each zookeeper instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true,
    (cloud.planton.apis.v1.commons.resource.field.options.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes schema-registry spec
message KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec {
  //flag to control if schema registry is created for the kafka-cluster.
  //defaults to "false".
  bool is_enabled = 1;

  //number of schema registry replicas.
  //recommended default value is "1".
  //this value has no effect if the is_schema_registry_enabled is set to false.
  int32 replicas = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //schema-registry container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  cloud.planton.apis.v1.commons.kubernetes.ContainerResources resources = 3 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];
}

//kafka-cluster kubernetes ingress spec
message KafkaClusterSpecKubernetesSpecIngressSpec {
  //toggle to control ingress
  bool is_enabled = 1;
  //ingress type
  cloud.planton.apis.v1.code2cloud.deploy.kubecluster.enums.workloadingress.KubernetesWorkloadIngressType ingress_type = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];
  //endpoint domain to be used for creating internal and external endpoints for kafka-cluster.
  //if the chosen ingress-type is `ingress-controller`, only tls enabled endpoint domains are allowed for creating kafka endpoints.
  string endpoint_domain_name = 3 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];
}

//kafka-cluster kubernetes status
message KafkaClusterStatusKubernetesStatus {
  //name of the kubernetes namespace in which the kafka-cluster is created.
  string namespace = 1;

  //sasl user name of kafka-cluster.
  //username will be automatically set as 'admin' while creating the kafka-cluster.
  string kafka_sasl_username = 2;

  //external hostname of kafka bootstrap server.
  string external_bootstrap_server_hostname = 3;

  //internal hostname of kafka bootstrap server.
  string internal_bootstrap_server_hostname = 4;

  //external url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string external_schema_registry_url = 5;

  //internal url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string internal_schema_registry_url = 6;

  //external url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string external_kowl_dashboard_url = 7;

  //internal url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string internal_kowl_dashboard_url = 8;
}

//wrapper for id field of kafka-cluster
message KafkaClusterId {
  string value = 1;
}

//list of kafka-clusters
message KafkaClusters {
  repeated KafkaCluster entries = 1;
}

//kafka-topic
message KafkaTopic {
  option (cloud.planton.apis.v1.commons.resource.metadata.options.id_prefix) = "kft";

  //topic name
  string name = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true,
    (cloud.planton.apis.v1.commons.resource.field.options.is_immutable) = true,
    (buf.validate.field).string.min_len = 1,
    (buf.validate.field).string.max_len = 249,
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Should start with an alphanumeric character",
      // https://regex101.com/r/cXprYc/1
      expression: "this.matches('^[a-zA-Z0-9].*$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Only alphanumeric and ('.', '_' and '-') characters are allowed",
      // https://regex101.com/r/hheWzb/1
      expression: "this.matches('^[a-zA-Z0-9._-]+$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Must not contain '..'",
      // https://regex101.com/r/ILMhoL/1
      expression: "!this.contains('..')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Must not contain non-ASCII characters",
      // https://regex101.com/r/FhCKeZ/1
      expression: "this.matches('^[\x00-\x7F]+$')"
    },
    (buf.validate.field).cel = {
      id: "topic.name",
      message: "Should end with an alphanumeric character",
      // https://regex101.com/r/DEA7Of/1
      expression: "this.matches('[a-zA-Z0-9]$')"
    }
  ];

  //topic id
  string id = 2 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_computed) = true
  ];

  //topic partitions.
  //recommended default is 1.
  int32 partitions = 4;

  //topic replicas.
  //recommended default is 1.
  int32 replicas = 5;

  //additional configuration of kafka topic
  //if not provided then default values will be set
  //for example default delete.policy is `delete` and can be set up as `compact`
  map<string, string> config = 6;
}

//wrapper for kafka topic config
message KafkaTopicConfig {
  map<string, string> value = 1;
}

//list of kafka topics
message KafkaTopics {
  repeated KafkaTopic entries = 1;
}

//wrapper for kafka topic id
message KafkaTopicId {
  string value = 1;
}

//wrapper for kafka-cluster password
message KafkaClusterPassword {
  string value = 1;
}

//input for command to add multiple kafka topics to a kafka-cluster
message AddKafkaTopicsCommandInput {
  //id of the kafka-cluster to which the kafka topics are added
  string kafka_cluster_id = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //list of kafka topics to be added to existing list of kafka topics
  repeated KafkaTopic kafka_topics = 2;
}

//response for paginated query to list kafka-clusters
message KafkaClusterList {
  int32 total_pages = 1;
  repeated KafkaCluster entries = 2;
}

//AddOrUpdateKafkaTopicCommandInput is used to encapsulate the details required
//for adding a new kafka-topic to a specific kafka-cluster, or updating
//an existing one. This message is typically used to transmit data between the client and
//server during an add or update operation concerning a specific kafka-topic
//associated with a particular kafka-cluster.
message AddOrUpdateKafkaTopicCommandInput {
  //The unique identifier for the kafka-cluster to which the kafka-topic
  // needs to be added or updated. This field must be populated with a valid
  //kafka-cluster ID, which can be obtained from the kafka-cluster entity itself.
  //The server uses this ID to identify the correct kafka-cluster where the
  //kafka-topic needs to be added or updated.
  string kafka_cluster_id = 1;

  //The kafka-topic that needs to be added or updated within the product
  //environment. This field should be populated with a valid KafkaTopic object,
  //which encapsulates the details of the kafka-topic. If an kafka-topic
  //with the kafka-topic-id already exists in the kafka-cluster, the value will be updated.
  //Otherwise, a new kafka-topic will be created with the provided details.
  KafkaTopic kafka_topic = 2;
}

//DeleteOrRestoreKafkaTopicCommandInput is used to encapsulate the details required for
//deleting or restoring a kafka-topic of a specific kafka-cluster.
//This message is typically used to transmit data between the client and the server
//during a delete or restore operation concerning a specific kafka-topic associated
//with a particular kafka-cluster.
message DeleteOrRestoreKafkaTopicCommandInput {
  //The unique identifier for the kafka-cluster from which the kafka-topic
  // needs to be deleted or restored. This field must be populated with a valid
  //kafka-cluster ID, which can be obtained from the kafka-cluster entity itself.
  //The server uses this ID to identify the correct kafka-cluster from which
  //the kafka-topic needs to be deleted or restored.
  string kafka_cluster_id = 1;

  //The kafka-topic-id of the kafka-topic that needs to be deleted or restored.
  //This field should be populated with a valid
  //kafka-topic-id, which can be obtained from the kafka-topic entity itself.
  //The server uses this kafka-topic-id to identify the correct kafka-topic that
  //needs to be deleted or restored.
  string kafka_topic_id = 2;
}

//KafkaTopicQueryInput is a message type that serves as input for queries
//related to Kafka topics within a specific Kafka cluster.
//It contains information about the specific Kafka cluster and the Kafka
//topic to be queried.
message KafkaTopicQueryInput {
  //Unique identifier of the Kafka cluster from which the Kafka topic
  //information is to be retrieved.
  //This field is required, as specified by the is_required field option.
  string kafka_cluster_id = 1 [
    (cloud.planton.apis.v1.commons.resource.field.options.is_required) = true
  ];

  //KafkaTopic object that represents the Kafka topic to be queried
  //in the Kafka cluster.
  //This encapsulates all the necessary information about the Kafka topic.
  KafkaTopic kafka_topic = 2;
}
