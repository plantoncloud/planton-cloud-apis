syntax = "proto3";

package planton.apis.proto.v1.deploy.opensource.kafka.rpc;

import "planton/apis/proto/v1/commons/audit/model.proto";
import "planton/apis/proto/v1/commons/kubernetes/model.proto";
import "planton/apis/proto/v1/commons/resource/field/options/resource_field_options.proto";
import "planton/apis/proto/v1/commons/resource/metadata/options/resource_metadata_options.proto";
import "planton/apis/proto/v1/commons/resource/model.proto";
import "planton/apis/proto/v1/commons/resource/options/resource_options.proto";
import "planton/apis/proto/v1/stack/rpc/model.proto";
import "planton/apis/proto/v1/commons/resource/owner/model.proto";

//kafka-cluster
message KafkaCluster {
  option (planton.apis.proto.v1.commons.resource.options.resource_type) = kafka_cluster;
  option (planton.apis.proto.v1.commons.resource.options.is_runnable) = true;
  option (planton.apis.proto.v1.commons.resource.options.owner).type = environment;
  option (planton.apis.proto.v1.commons.resource.options.owner).id_field_path = "spec.owner.environment_id";

  option (planton.apis.proto.v1.commons.resource.metadata.options.is_id_required) = false;
  option (planton.apis.proto.v1.commons.resource.metadata.options.id_prefix) = "kfc";
  //id format "kfc-<environment-id>-<kafka-cluster-name>"
  option (planton.apis.proto.v1.commons.resource.metadata.options.is_id_computed) = true;
  //https://regex101.com/r/QbMSjf/1
  option (planton.apis.proto.v1.commons.resource.metadata.options.name_regex) = "^[a-z][a-z0-9]*(-[a-z0-9]+)*$";
  option (planton.apis.proto.v1.commons.resource.metadata.options.name_min_length) = 1;
  option (planton.apis.proto.v1.commons.resource.metadata.options.name_max_length) = 10;
  option (planton.apis.proto.v1.commons.resource.metadata.options.name_constraints_description) = "At least 1 character. Lowercase letters, numbers, and hyphens. Must start with lowercase letter. Must not start or end with hyphen. Length must be under 10 characters.";

  //resource api-version
  string api_version = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //resource kind
  string kind = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //resource metadata
  planton.apis.proto.v1.commons.resource.Metadata metadata = 3;

  //spec
  KafkaClusterSpec spec = 4;

  //status
  KafkaClusterStatus status = 5;
}

//kafka-cluster spec
message KafkaClusterSpec {
  //resource parent
  planton.apis.proto.v1.commons.resource.owner.EnvironmentResourceOwner owner = 1;

  //list of kafka topics.
  repeated KafkaTopic kafka_topics = 2;

  //kubernetes spec
  KafkaClusterSpecKubernetesSpec kubernetes = 3;
}

//kafka-cluster status
message KafkaClusterStatus {
  // resource lifecycle
  planton.apis.proto.v1.commons.resource.RunnableResourceLifecycle lifecycle = 99;

  // system audit info
  planton.apis.proto.v1.commons.audit.SysAudit sys_audit = 98;

  // stack-job
  planton.apis.proto.v1.stack.rpc.StackJob stack_job = 97;

  //kafka-cluster kubernetes status
  KafkaClusterStatusKubernetesStatus kubernetes = 1;
}

//kafka-cluster kubernetes spec
message KafkaClusterSpecKubernetesSpec {
  //kafka-broker container spec
  KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec kafka_broker_container = 1;

  //zookeeper container spec
  KafkaClusterSpecKubernetesSpecZookeeperContainerSpec zookeeper_container = 2;

  //schema-registry container spec
  KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec schema_registry_container = 3;

  //kafka-cluster ingress spec
  KafkaClusterSpecKubernetesSpecIngressSpec ingress = 4;

  //flag to control if kowl dashboard is deployed for the kafka-cluster.
  //defaults to "false".
  bool is_kowl_dashboard_enabled = 5;
}

//kafka-cluster kubernetes kafka-broker spec
message KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpec {
  //(optional for create) number of brokers required to setup kafka-cluster.
  //defaults value "1" is set if client sets the value to 0.
  //recommended default value is "1".
  int32 replicas = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //kafka broker container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  planton.apis.proto.v1.commons.kubernetes.ContainerResources resources = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //size of the disk to be attached to each broker instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true,
    (planton.apis.proto.v1.commons.resource.field.options.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes zookeeper spec
message KafkaClusterSpecKubernetesSpecZookeeperContainerSpec {
  //number or zookeeper container replicas
  //zookeeper requires latest 3 replicas for high availability(ha) mode.
  //zookeeper is built using raft consensus algorithm.
  //refer to https://raft.github.io/ to learn more on how replica count affect availability.
  int32 replicas = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //zookeeper container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  planton.apis.proto.v1.commons.kubernetes.ContainerResources resources = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //size of the disk to be attached to each zookeeper instance. ex: 30Gi
  //defaults value is set if not provided by the client.
  string disk_size = 3 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true,
    (planton.apis.proto.v1.commons.resource.field.options.string_default) = "1Gi"
  ];
}

//kafka-cluster kubernetes schema-registry spec
message KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpec {
  //flag to control if schema registry is created for the kafka-cluster.
  //defaults to "false".
  bool is_enabled = 1;

  //number of schema registry replicas.
  //recommended default value is "1".
  //this value has no effect if the is_schema_registry_enabled is set to false.
  int32 replicas = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //schema-registry container cpu and memory resources.
  //recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  planton.apis.proto.v1.commons.kubernetes.ContainerResources resources = 3 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];
}

//kafka-cluster kubernetes ingress spec
message KafkaClusterSpecKubernetesSpecIngressSpec {
  //standard-endpoint domain to be used for creating internal and external endpoints for kafka-cluster.
  //only tls enabled standard-endpoints are eligible for creating kafka endpoints.
  string standard_endpoint_id = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //endpoint-domain-name used for creating kafka-cluster endpoints.
  //value is computed from the configured standard-endpoint.
  string endpoint_domain_name = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_computed) = true
  ];
}

//kafka-cluster kubernetes status
message KafkaClusterStatusKubernetesStatus {
  //name of the kubernetes namespace in which the kafka-cluster is created.
  string namespace = 1;

  //sasl user name of kafka-cluster.
  //username will be automatically set as 'admin' while creating the kafka-cluster.
  string kafka_sasl_username = 2;

  //external hostname of kafka bootstrap server.
  string external_bootstrap_server_hostname = 3;

  //internal hostname of kafka bootstrap server.
  string internal_bootstrap_server_hostname = 4;

  //external url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string external_schema_registry_url = 5;

  //internal url of schema registry.
  //this is set to empty when schema registry is not enabled.
  string internal_schema_registry_url = 6;

  //external url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string external_kowl_dashboard_url = 7;

  //internal url to access kowl dashboard.
  //this is set to empty when kowl dashboard is not enabled.
  string internal_kowl_dashboard_url = 8;
}

//wrapper for id field of kafka-cluster
message KafkaClusterId {
  string value = 1;
}

//list of kafka-clusters
message KafkaClusters {
  repeated KafkaCluster entries = 1;
}

//kafka-topic
message KafkaTopic {
  option (planton.apis.proto.v1.commons.resource.options.resource_type) = RESOURCE_TYPE_UNSPECIFIED;

  option (planton.apis.proto.v1.commons.resource.metadata.options.id_prefix) = "kft";

  planton.apis.proto.v1.commons.audit.SysAudit sys_audit = 99;

  //topic name
  string name = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true,
    (planton.apis.proto.v1.commons.resource.field.options.is_immutable) = true,
    (planton.apis.proto.v1.commons.resource.field.options.string_regex) = "^(?![-._])([a-zA-Z0-9._-]*[a-zA-Z0-9-])([a-zA-Z0-9._-]*[a-zA-Z0-9])$",
    (planton.apis.proto.v1.commons.resource.field.options.field_constraints_description) = "Topic names should start with an alphanumeric character, be 1-249 characters long, can include '.', '_', and '-' (but not at the start or end), and must not contain '..' or non-ASCII characters."
  ];

  //topic id
  string id = 2 [
    (planton.apis.proto.v1.commons.resource.field.options.is_computed) = true
  ];

  //topic partitions.
  //recommended default is 1.
  int32 partitions = 4;

  //topic replicas.
  //recommended default is 1.
  int32 replicas = 5;

  //additional configuration of kafka topic
  //if not provided then default values will be set
  //for example default delete.policy is `delete` and can be set up as `compact`
  map<string, string> config = 6;
}

//wrapper for kafka topic config
message KafkaTopicConfig {
  map<string, string> value = 1;
}

//list of kafka topics
message KafkaTopics {
  repeated KafkaTopic entries = 1;
}

//wrapper for kafka topic id
message KafkaTopicId {
  string value = 1;
}

//wrapper for kafka-cluster password
message KafkaClusterPassword {
  string value = 1;
}

//input for command to add multiple kafka topics to a kafka-cluster
message AddKafkaTopicsCommandInput {
  //id of the kafka-cluster to which the kafka topics are added
  string kafka_cluster_id = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //list of kafka topics to be added to existing list of kafka topics
  repeated KafkaTopic kafka_topics = 2;
}

//response for paginated query to list kafka-clusters
message KafkaClusterList {
  int32 total_pages = 1;
  repeated KafkaCluster entries = 2;
}

//AddOrUpdateKafkaTopicCommandInput is used to encapsulate the details required
//for adding a new kafka-topic to a specific kafka-cluster, or updating
//an existing one. This message is typically used to transmit data between the client and
//server during an add or update operation concerning a specific kafka-topic
//associated with a particular kafka-cluster.
message AddOrUpdateKafkaTopicCommandInput {
  //The unique identifier for the kafka-cluster to which the kafka-topic
  // needs to be added or updated. This field must be populated with a valid
  //kafka-cluster ID, which can be obtained from the kafka-cluster entity itself.
  //The server uses this ID to identify the correct kafka-cluster where the
  //kafka-topic needs to be added or updated.
  string kafka_cluster_id = 1;

  //The kafka-topic that needs to be added or updated within the product
  //environment. This field should be populated with a valid KafkaTopic object,
  //which encapsulates the details of the kafka-topic. If an kafka-topic
  //with the kafka-topic-id already exists in the kafka-cluster, the value will be updated.
  //Otherwise, a new kafka-topic will be created with the provided details.
  KafkaTopic kafka_topic = 2;
}

//DeleteOrRestoreKafkaTopicCommandInput is used to encapsulate the details required for
//deleting or restoring a kafka-topic of a specific kafka-cluster.
//This message is typically used to transmit data between the client and the server
//during a delete or restore operation concerning a specific kafka-topic associated
//with a particular kafka-cluster.
message DeleteOrRestoreKafkaTopicCommandInput {
  //The unique identifier for the kafka-cluster from which the kafka-topic
  // needs to be deleted or restored. This field must be populated with a valid
  //kafka-cluster ID, which can be obtained from the kafka-cluster entity itself.
  //The server uses this ID to identify the correct kafka-cluster from which
  //the kafka-topic needs to be deleted or restored.
  string kafka_cluster_id = 1;

  //The kafka-topic-id of the kafka-topic that needs to be deleted or restored.
  //This field should be populated with a valid
  //kafka-topic-id, which can be obtained from the kafka-topic entity itself.
  //The server uses this kafka-topic-id to identify the correct kafka-topic that
  //needs to be deleted or restored.
  string kafka_topic_id = 2;
}

//KafkaTopicQueryInput is a message type that serves as input for queries
//related to Kafka topics within a specific Kafka cluster.
//It contains information about the specific Kafka cluster and the Kafka
//topic to be queried.
message KafkaTopicQueryInput {
  //Unique identifier of the Kafka cluster from which the Kafka topic
  //information is to be retrieved.
  //This field is required, as specified by the is_required field option.
  string kafka_cluster_id = 1 [
    (planton.apis.proto.v1.commons.resource.field.options.is_required) = true
  ];

  //KafkaTopic object that represents the Kafka topic to be queried
  //in the Kafka cluster.
  //This encapsulates all the necessary information about the Kafka topic.
  KafkaTopic kafka_topic = 2;
}
