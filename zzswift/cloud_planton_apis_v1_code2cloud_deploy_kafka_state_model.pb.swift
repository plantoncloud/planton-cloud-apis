// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: cloud/planton/apis/v1/code2cloud/deploy/kafka/state/model.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

///kafka-cluster state
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///event-type
  public var eventType: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_Enums_KafkaClusterEventType = .unspecified

  ///resource api version
  public var apiVersion: String = String()

  ///resource kind
  public var kind: String = String()

  ///resource metadata
  public var metadata: Cloud_Planton_Apis_V1_Commons_Resource_Metadata {
    get {return _metadata ?? Cloud_Planton_Apis_V1_Commons_Resource_Metadata()}
    set {_metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return self._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {self._metadata = nil}

  ///spec
  public var spec: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState {
    get {return _spec ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState()}
    set {_spec = newValue}
  }
  /// Returns true if `spec` has been explicitly set.
  public var hasSpec: Bool {return self._spec != nil}
  /// Clears the value of `spec`. Subsequent reads from it will return its default value.
  public mutating func clearSpec() {self._spec = nil}

  ///status
  public var status: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState {
    get {return _status ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState()}
    set {_status = newValue}
  }
  /// Returns true if `status` has been explicitly set.
  public var hasStatus: Bool {return self._status != nil}
  /// Clears the value of `status`. Subsequent reads from it will return its default value.
  public mutating func clearStatus() {self._status = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _metadata: Cloud_Planton_Apis_V1_Commons_Resource_Metadata? = nil
  fileprivate var _spec: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState? = nil
  fileprivate var _status: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState? = nil
}

///KafkaClusterSpecState
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///resource parent
  public var owner: Cloud_Planton_Apis_V1_Commons_Resource_Owner_EnvironmentResourceOwner {
    get {return _owner ?? Cloud_Planton_Apis_V1_Commons_Resource_Owner_EnvironmentResourceOwner()}
    set {_owner = newValue}
  }
  /// Returns true if `owner` has been explicitly set.
  public var hasOwner: Bool {return self._owner != nil}
  /// Clears the value of `owner`. Subsequent reads from it will return its default value.
  public mutating func clearOwner() {self._owner = nil}

  ///list of kafka topics.
  public var kafkaTopics: [Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState] = []

  ///kubernetes spec
  public var kubernetes: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState {
    get {return _kubernetes ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState()}
    set {_kubernetes = newValue}
  }
  /// Returns true if `kubernetes` has been explicitly set.
  public var hasKubernetes: Bool {return self._kubernetes != nil}
  /// Clears the value of `kubernetes`. Subsequent reads from it will return its default value.
  public mutating func clearKubernetes() {self._kubernetes = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _owner: Cloud_Planton_Apis_V1_Commons_Resource_Owner_EnvironmentResourceOwner? = nil
  fileprivate var _kubernetes: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState? = nil
}

///kafka-cluster status state
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// resource lifecycle
  public var lifecycle: Cloud_Planton_Apis_V1_Commons_Resource_RunnableResourceLifecycle {
    get {return _storage._lifecycle ?? Cloud_Planton_Apis_V1_Commons_Resource_RunnableResourceLifecycle()}
    set {_uniqueStorage()._lifecycle = newValue}
  }
  /// Returns true if `lifecycle` has been explicitly set.
  public var hasLifecycle: Bool {return _storage._lifecycle != nil}
  /// Clears the value of `lifecycle`. Subsequent reads from it will return its default value.
  public mutating func clearLifecycle() {_uniqueStorage()._lifecycle = nil}

  /// system audit info
  public var sysAudit: Cloud_Planton_Apis_V1_Commons_Audit_SysAudit {
    get {return _storage._sysAudit ?? Cloud_Planton_Apis_V1_Commons_Audit_SysAudit()}
    set {_uniqueStorage()._sysAudit = newValue}
  }
  /// Returns true if `sysAudit` has been explicitly set.
  public var hasSysAudit: Bool {return _storage._sysAudit != nil}
  /// Clears the value of `sysAudit`. Subsequent reads from it will return its default value.
  public mutating func clearSysAudit() {_uniqueStorage()._sysAudit = nil}

  /// id of the stack-job
  public var stackJobID: String {
    get {return _storage._stackJobID}
    set {_uniqueStorage()._stackJobID = newValue}
  }

  ///kafka-cluster kubernetes status
  public var kubernetes: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState {
    get {return _storage._kubernetes ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState()}
    set {_uniqueStorage()._kubernetes = newValue}
  }
  /// Returns true if `kubernetes` has been explicitly set.
  public var hasKubernetes: Bool {return _storage._kubernetes != nil}
  /// Clears the value of `kubernetes`. Subsequent reads from it will return its default value.
  public mutating func clearKubernetes() {_uniqueStorage()._kubernetes = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

///kafka-cluster kubernetes spec
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///kafka-broker container spec
  public var kafkaBrokerContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState {
    get {return _storage._kafkaBrokerContainer ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState()}
    set {_uniqueStorage()._kafkaBrokerContainer = newValue}
  }
  /// Returns true if `kafkaBrokerContainer` has been explicitly set.
  public var hasKafkaBrokerContainer: Bool {return _storage._kafkaBrokerContainer != nil}
  /// Clears the value of `kafkaBrokerContainer`. Subsequent reads from it will return its default value.
  public mutating func clearKafkaBrokerContainer() {_uniqueStorage()._kafkaBrokerContainer = nil}

  ///zookeeper container spec
  public var zookeeperContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState {
    get {return _storage._zookeeperContainer ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState()}
    set {_uniqueStorage()._zookeeperContainer = newValue}
  }
  /// Returns true if `zookeeperContainer` has been explicitly set.
  public var hasZookeeperContainer: Bool {return _storage._zookeeperContainer != nil}
  /// Clears the value of `zookeeperContainer`. Subsequent reads from it will return its default value.
  public mutating func clearZookeeperContainer() {_uniqueStorage()._zookeeperContainer = nil}

  ///schema-registry container spec
  public var schemaRegistryContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState {
    get {return _storage._schemaRegistryContainer ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState()}
    set {_uniqueStorage()._schemaRegistryContainer = newValue}
  }
  /// Returns true if `schemaRegistryContainer` has been explicitly set.
  public var hasSchemaRegistryContainer: Bool {return _storage._schemaRegistryContainer != nil}
  /// Clears the value of `schemaRegistryContainer`. Subsequent reads from it will return its default value.
  public mutating func clearSchemaRegistryContainer() {_uniqueStorage()._schemaRegistryContainer = nil}

  ///kafka-cluster ingress spec
  public var ingress: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState {
    get {return _storage._ingress ?? Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState()}
    set {_uniqueStorage()._ingress = newValue}
  }
  /// Returns true if `ingress` has been explicitly set.
  public var hasIngress: Bool {return _storage._ingress != nil}
  /// Clears the value of `ingress`. Subsequent reads from it will return its default value.
  public mutating func clearIngress() {_uniqueStorage()._ingress = nil}

  ///flag to control if kowl dashboard is deployed for the kafka-cluster.
  ///defaults to "false".
  public var isKowlDashboardEnabled: Bool {
    get {return _storage._isKowlDashboardEnabled}
    set {_uniqueStorage()._isKowlDashboardEnabled = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

///kafka-cluster kubernetes kafka-broker spec
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///(optional for create) number of brokers required to setup kafka-cluster.
  ///defaults value "1" is set if client sets the value to 0.
  ///recommended default value is "1".
  public var replicas: Int32 = 0

  ///kafka broker container cpu and memory resources.
  ///recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  public var resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources {
    get {return _resources ?? Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources()}
    set {_resources = newValue}
  }
  /// Returns true if `resources` has been explicitly set.
  public var hasResources: Bool {return self._resources != nil}
  /// Clears the value of `resources`. Subsequent reads from it will return its default value.
  public mutating func clearResources() {self._resources = nil}

  ///size of the disk to be attached to each broker instance. ex: 30Gi
  ///defaults value is set if not provided by the client.
  public var diskSize: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources? = nil
}

///kafka-cluster kubernetes zookeeper spec
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///number or zookeeper container replicas
  ///zookeeper requires latest 3 replicas for high availability(ha) mode.
  ///zookeeper is built using raft consensus algorithm.
  ///refer to https://raft.github.io/ to learn more on how replica count affect availability.
  public var replicas: Int32 = 0

  ///zookeeper container cpu and memory resources.
  ///recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  public var resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources {
    get {return _resources ?? Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources()}
    set {_resources = newValue}
  }
  /// Returns true if `resources` has been explicitly set.
  public var hasResources: Bool {return self._resources != nil}
  /// Clears the value of `resources`. Subsequent reads from it will return its default value.
  public mutating func clearResources() {self._resources = nil}

  ///size of the disk to be attached to each zookeeper instance. ex: 30Gi
  ///defaults value is set if not provided by the client.
  public var diskSize: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources? = nil
}

///kafka-cluster kubernetes schema-registry spec
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///flag to control if schema registry is created for the kafka-cluster.
  ///defaults to "false".
  public var isEnabled: Bool = false

  ///number of schema registry replicas.
  ///recommended default value is "1".
  ///this value has no effect if the is_schema_registry_enabled is set to false.
  public var replicas: Int32 = 0

  ///schema-registry container cpu and memory resources.
  ///recommended default "cpu-requests: 50m, memory-requests: 256Mi, cpu-limits: 1, memory-limits: 1Gi"
  public var resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources {
    get {return _resources ?? Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources()}
    set {_resources = newValue}
  }
  /// Returns true if `resources` has been explicitly set.
  public var hasResources: Bool {return self._resources != nil}
  /// Clears the value of `resources`. Subsequent reads from it will return its default value.
  public mutating func clearResources() {self._resources = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resources: Cloud_Planton_Apis_V1_Commons_Kubernetes_ContainerResources? = nil
}

///kafka-cluster kubernetes ingress spec
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///standard-endpoint domain to be used for creating internal and external endpoints for kafka-cluster.
  ///only tls enabled standard-endpoints are eligible for creating kafka endpoints.
  public var standardEndpointID: String = String()

  ///endpoint-domain-name used for creating kafka-cluster endpoints.
  ///value is computed from the configured standard-endpoint.
  public var endpointDomainName: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

///kafka-cluster kubernetes status
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///name of the kubernetes namespace in which the kafka-cluster is created.
  public var namespace: String = String()

  ///sasl user name of kafka-cluster.
  ///username will be automatically set as 'admin' while creating the kafka-cluster.
  public var kafkaSaslUsername: String = String()

  ///external hostname of kafka bootstrap server.
  public var externalBootstrapServerHostname: String = String()

  ///internal hostname of kafka bootstrap server.
  public var internalBootstrapServerHostname: String = String()

  ///external url of schema registry.
  ///this is set to empty when schema registry is not enabled.
  public var externalSchemaRegistryURL: String = String()

  ///internal url of schema registry.
  ///this is set to empty when schema registry is not enabled.
  public var internalSchemaRegistryURL: String = String()

  ///external url to access kowl dashboard.
  ///this is set to empty when kowl dashboard is not enabled.
  public var externalKowlDashboardURL: String = String()

  ///internal url to access kowl dashboard.
  ///this is set to empty when kowl dashboard is not enabled.
  public var internalKowlDashboardURL: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

///kafka-topic state
public struct Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///system audit info
  public var sysAudit: Cloud_Planton_Apis_V1_Commons_Audit_SysAudit {
    get {return _sysAudit ?? Cloud_Planton_Apis_V1_Commons_Audit_SysAudit()}
    set {_sysAudit = newValue}
  }
  /// Returns true if `sysAudit` has been explicitly set.
  public var hasSysAudit: Bool {return self._sysAudit != nil}
  /// Clears the value of `sysAudit`. Subsequent reads from it will return its default value.
  public mutating func clearSysAudit() {self._sysAudit = nil}

  ///topic name
  public var name: String = String()

  ///topic id
  public var id: String = String()

  ///topic partitions.
  ///recommended default is 1.
  public var partitions: Int32 = 0

  ///topic replicas.
  ///recommended default is 1.
  public var replicas: Int32 = 0

  ///additional configuration of kafka topic
  ///if not provided then default values will be set
  ///for example default delete.policy is `delete` and can be set up as `compact`
  public var config: Dictionary<String,String> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _sysAudit: Cloud_Planton_Apis_V1_Commons_Audit_SysAudit? = nil
}

#if swift(>=5.5) && canImport(_Concurrency)
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState: @unchecked Sendable {}
extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState: @unchecked Sendable {}
#endif  // swift(>=5.5) && canImport(_Concurrency)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "cloud.planton.apis.v1.code2cloud.deploy.kafka.state"

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    99: .standard(proto: "event_type"),
    1: .standard(proto: "api_version"),
    2: .same(proto: "kind"),
    3: .same(proto: "metadata"),
    4: .same(proto: "spec"),
    5: .same(proto: "status"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.apiVersion) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._spec) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._status) }()
      case 99: try { try decoder.decodeSingularEnumField(value: &self.eventType) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.apiVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.apiVersion, fieldNumber: 1)
    }
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 2)
    }
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._spec {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._status {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if self.eventType != .unspecified {
      try visitor.visitSingularEnumField(value: self.eventType, fieldNumber: 99)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterState) -> Bool {
    if lhs.eventType != rhs.eventType {return false}
    if lhs.apiVersion != rhs.apiVersion {return false}
    if lhs.kind != rhs.kind {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs._spec != rhs._spec {return false}
    if lhs._status != rhs._status {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "owner"),
    2: .standard(proto: "kafka_topics"),
    3: .same(proto: "kubernetes"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._owner) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.kafkaTopics) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._kubernetes) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._owner {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.kafkaTopics.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.kafkaTopics, fieldNumber: 2)
    }
    try { if let v = self._kubernetes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecState) -> Bool {
    if lhs._owner != rhs._owner {return false}
    if lhs.kafkaTopics != rhs.kafkaTopics {return false}
    if lhs._kubernetes != rhs._kubernetes {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterStatusState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    99: .same(proto: "lifecycle"),
    98: .standard(proto: "sys_audit"),
    97: .standard(proto: "stack_job_id"),
    1: .same(proto: "kubernetes"),
  ]

  fileprivate class _StorageClass {
    var _lifecycle: Cloud_Planton_Apis_V1_Commons_Resource_RunnableResourceLifecycle? = nil
    var _sysAudit: Cloud_Planton_Apis_V1_Commons_Audit_SysAudit? = nil
    var _stackJobID: String = String()
    var _kubernetes: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _lifecycle = source._lifecycle
      _sysAudit = source._sysAudit
      _stackJobID = source._stackJobID
      _kubernetes = source._kubernetes
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._kubernetes) }()
        case 97: try { try decoder.decodeSingularStringField(value: &_storage._stackJobID) }()
        case 98: try { try decoder.decodeSingularMessageField(value: &_storage._sysAudit) }()
        case 99: try { try decoder.decodeSingularMessageField(value: &_storage._lifecycle) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._kubernetes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._stackJobID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._stackJobID, fieldNumber: 97)
      }
      try { if let v = _storage._sysAudit {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 98)
      } }()
      try { if let v = _storage._lifecycle {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 99)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusState) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._lifecycle != rhs_storage._lifecycle {return false}
        if _storage._sysAudit != rhs_storage._sysAudit {return false}
        if _storage._stackJobID != rhs_storage._stackJobID {return false}
        if _storage._kubernetes != rhs_storage._kubernetes {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecKubernetesSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "kafka_broker_container"),
    2: .standard(proto: "zookeeper_container"),
    3: .standard(proto: "schema_registry_container"),
    4: .same(proto: "ingress"),
    5: .standard(proto: "is_kowl_dashboard_enabled"),
  ]

  fileprivate class _StorageClass {
    var _kafkaBrokerContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState? = nil
    var _zookeeperContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState? = nil
    var _schemaRegistryContainer: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState? = nil
    var _ingress: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState? = nil
    var _isKowlDashboardEnabled: Bool = false

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _kafkaBrokerContainer = source._kafkaBrokerContainer
      _zookeeperContainer = source._zookeeperContainer
      _schemaRegistryContainer = source._schemaRegistryContainer
      _ingress = source._ingress
      _isKowlDashboardEnabled = source._isKowlDashboardEnabled
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._kafkaBrokerContainer) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._zookeeperContainer) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._schemaRegistryContainer) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._ingress) }()
        case 5: try { try decoder.decodeSingularBoolField(value: &_storage._isKowlDashboardEnabled) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._kafkaBrokerContainer {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      try { if let v = _storage._zookeeperContainer {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._schemaRegistryContainer {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      try { if let v = _storage._ingress {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      if _storage._isKowlDashboardEnabled != false {
        try visitor.visitSingularBoolField(value: _storage._isKowlDashboardEnabled, fieldNumber: 5)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecState) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kafkaBrokerContainer != rhs_storage._kafkaBrokerContainer {return false}
        if _storage._zookeeperContainer != rhs_storage._zookeeperContainer {return false}
        if _storage._schemaRegistryContainer != rhs_storage._schemaRegistryContainer {return false}
        if _storage._ingress != rhs_storage._ingress {return false}
        if _storage._isKowlDashboardEnabled != rhs_storage._isKowlDashboardEnabled {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "replicas"),
    2: .same(proto: "resources"),
    3: .standard(proto: "disk_size"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.replicas) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._resources) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.diskSize) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.replicas != 0 {
      try visitor.visitSingularInt32Field(value: self.replicas, fieldNumber: 1)
    }
    try { if let v = self._resources {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.diskSize.isEmpty {
      try visitor.visitSingularStringField(value: self.diskSize, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecKafkaBrokerContainerSpecState) -> Bool {
    if lhs.replicas != rhs.replicas {return false}
    if lhs._resources != rhs._resources {return false}
    if lhs.diskSize != rhs.diskSize {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "replicas"),
    2: .same(proto: "resources"),
    3: .standard(proto: "disk_size"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.replicas) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._resources) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.diskSize) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.replicas != 0 {
      try visitor.visitSingularInt32Field(value: self.replicas, fieldNumber: 1)
    }
    try { if let v = self._resources {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.diskSize.isEmpty {
      try visitor.visitSingularStringField(value: self.diskSize, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecZookeeperContainerSpecState) -> Bool {
    if lhs.replicas != rhs.replicas {return false}
    if lhs._resources != rhs._resources {return false}
    if lhs.diskSize != rhs.diskSize {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "is_enabled"),
    2: .same(proto: "replicas"),
    3: .same(proto: "resources"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.isEnabled) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.replicas) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._resources) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.isEnabled != false {
      try visitor.visitSingularBoolField(value: self.isEnabled, fieldNumber: 1)
    }
    if self.replicas != 0 {
      try visitor.visitSingularInt32Field(value: self.replicas, fieldNumber: 2)
    }
    try { if let v = self._resources {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecSchemaRegistryContainerSpecState) -> Bool {
    if lhs.isEnabled != rhs.isEnabled {return false}
    if lhs.replicas != rhs.replicas {return false}
    if lhs._resources != rhs._resources {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterSpecKubernetesSpecIngressSpecState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "standard_endpoint_id"),
    2: .standard(proto: "endpoint_domain_name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.standardEndpointID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.endpointDomainName) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.standardEndpointID.isEmpty {
      try visitor.visitSingularStringField(value: self.standardEndpointID, fieldNumber: 1)
    }
    if !self.endpointDomainName.isEmpty {
      try visitor.visitSingularStringField(value: self.endpointDomainName, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterSpecKubernetesSpecIngressSpecState) -> Bool {
    if lhs.standardEndpointID != rhs.standardEndpointID {return false}
    if lhs.endpointDomainName != rhs.endpointDomainName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaClusterStatusKubernetesStatusState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "namespace"),
    2: .standard(proto: "kafka_sasl_username"),
    3: .standard(proto: "external_bootstrap_server_hostname"),
    4: .standard(proto: "internal_bootstrap_server_hostname"),
    5: .standard(proto: "external_schema_registry_url"),
    6: .standard(proto: "internal_schema_registry_url"),
    7: .standard(proto: "external_kowl_dashboard_url"),
    8: .standard(proto: "internal_kowl_dashboard_url"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.namespace) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.kafkaSaslUsername) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.externalBootstrapServerHostname) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.internalBootstrapServerHostname) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.externalSchemaRegistryURL) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.internalSchemaRegistryURL) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.externalKowlDashboardURL) }()
      case 8: try { try decoder.decodeSingularStringField(value: &self.internalKowlDashboardURL) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.namespace.isEmpty {
      try visitor.visitSingularStringField(value: self.namespace, fieldNumber: 1)
    }
    if !self.kafkaSaslUsername.isEmpty {
      try visitor.visitSingularStringField(value: self.kafkaSaslUsername, fieldNumber: 2)
    }
    if !self.externalBootstrapServerHostname.isEmpty {
      try visitor.visitSingularStringField(value: self.externalBootstrapServerHostname, fieldNumber: 3)
    }
    if !self.internalBootstrapServerHostname.isEmpty {
      try visitor.visitSingularStringField(value: self.internalBootstrapServerHostname, fieldNumber: 4)
    }
    if !self.externalSchemaRegistryURL.isEmpty {
      try visitor.visitSingularStringField(value: self.externalSchemaRegistryURL, fieldNumber: 5)
    }
    if !self.internalSchemaRegistryURL.isEmpty {
      try visitor.visitSingularStringField(value: self.internalSchemaRegistryURL, fieldNumber: 6)
    }
    if !self.externalKowlDashboardURL.isEmpty {
      try visitor.visitSingularStringField(value: self.externalKowlDashboardURL, fieldNumber: 7)
    }
    if !self.internalKowlDashboardURL.isEmpty {
      try visitor.visitSingularStringField(value: self.internalKowlDashboardURL, fieldNumber: 8)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaClusterStatusKubernetesStatusState) -> Bool {
    if lhs.namespace != rhs.namespace {return false}
    if lhs.kafkaSaslUsername != rhs.kafkaSaslUsername {return false}
    if lhs.externalBootstrapServerHostname != rhs.externalBootstrapServerHostname {return false}
    if lhs.internalBootstrapServerHostname != rhs.internalBootstrapServerHostname {return false}
    if lhs.externalSchemaRegistryURL != rhs.externalSchemaRegistryURL {return false}
    if lhs.internalSchemaRegistryURL != rhs.internalSchemaRegistryURL {return false}
    if lhs.externalKowlDashboardURL != rhs.externalKowlDashboardURL {return false}
    if lhs.internalKowlDashboardURL != rhs.internalKowlDashboardURL {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".KafkaTopicState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    99: .standard(proto: "sys_audit"),
    1: .same(proto: "name"),
    2: .same(proto: "id"),
    4: .same(proto: "partitions"),
    5: .same(proto: "replicas"),
    6: .same(proto: "config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.id) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.partitions) }()
      case 5: try { try decoder.decodeSingularInt32Field(value: &self.replicas) }()
      case 6: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.config) }()
      case 99: try { try decoder.decodeSingularMessageField(value: &self._sysAudit) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.id.isEmpty {
      try visitor.visitSingularStringField(value: self.id, fieldNumber: 2)
    }
    if self.partitions != 0 {
      try visitor.visitSingularInt32Field(value: self.partitions, fieldNumber: 4)
    }
    if self.replicas != 0 {
      try visitor.visitSingularInt32Field(value: self.replicas, fieldNumber: 5)
    }
    if !self.config.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.config, fieldNumber: 6)
    }
    try { if let v = self._sysAudit {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 99)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState, rhs: Cloud_Planton_Apis_V1_Code2cloud_Deploy_Kafka_State_KafkaTopicState) -> Bool {
    if lhs._sysAudit != rhs._sysAudit {return false}
    if lhs.name != rhs.name {return false}
    if lhs.id != rhs.id {return false}
    if lhs.partitions != rhs.partitions {return false}
    if lhs.replicas != rhs.replicas {return false}
    if lhs.config != rhs.config {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
